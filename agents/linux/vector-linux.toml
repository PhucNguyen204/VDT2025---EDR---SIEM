# ====================================================================
# VECTOR EDR AGENT - LINUX CONFIGURATION  
# ====================================================================
# Tác giả: Senior Software Engineer - EDR Platform Team
# Mô tả: Cấu hình Vector agent để thu thập, xử lý và gửi log từ Linux endpoint
# Phiên bản: 1.0.0
# Ngày tạo: 2024-01-01
# ====================================================================

# --------------------------------------------------------------------
# GLOBAL CONFIGURATION - CẤU HÌNH TOÀN CỤC
# --------------------------------------------------------------------
# Vector sẽ chạy với các thông số tối ưu cho môi trường production

# Đường dẫn data directory của Vector
data_dir = "/var/lib/vector/data"

# Cấu hình log schema
[log_schema]
host_key = "host.name"
message_key = "message"
timestamp_key = "@timestamp"

# ====================================================================
# SOURCES - NGUỒN THU THẬP DỮ LIỆU
# ====================================================================
# Phần này định nghĩa các nguồn dữ liệu quan trọng từ Linux endpoint

# --------------------------------------------------------------------
# [1] SYSTEM AUTHENTICATION LOGS - LOG XÁC THỰC HỆ THỐNG
# --------------------------------------------------------------------
[sources.linux_auth_logs]
type = "file"
# Theo dõi các file log xác thực quan trọng (khác nhau tùy distro)
include = [
    "/var/log/auth.log",        # Ubuntu/Debian
    "/var/log/secure",          # RHEL/CentOS/Fedora
    "/var/log/messages"         # Fallback cho một số hệ thống
]

# Cấu hình đọc file hiệu quả
read_from = "beginning"     # Đọc từ đầu file khi khởi động lần đầu
max_read_bytes = 65536      # Buffer 64KB
max_line_bytes = 32768      # Max line size 32KB
start_at_beginning = false  # Chỉ đọc log mới sau khi agent start

# Fingerprinting để theo dõi file rotation
fingerprint.strategy = "device_and_inode"

# --------------------------------------------------------------------
# [2] SYSTEM LOGS - LOG HỆ THỐNG CHUNG
# --------------------------------------------------------------------
[sources.linux_system_logs]
type = "file"
include = [
    "/var/log/syslog",          # Ubuntu/Debian system logs
    "/var/log/messages",        # RHEL/CentOS system logs
    "/var/log/kern.log"         # Kernel logs
]

# Chỉ thu thập log từ 1 giờ trước để tránh quá tải khi khởi động
ignore_older_secs = 3600
read_from = "end"

# --------------------------------------------------------------------
# [3] SYSTEMD JOURNAL - JOURNALD LOGS (MODERN LINUX)
# --------------------------------------------------------------------
[sources.linux_journald]
type = "journald"

# Thu thập từ tất cả units, nhưng có filter sau này
# Journald là nguồn dữ liệu tập trung trên hệ thống hiện đại
journal_directory = "/var/log/journal"

# Chỉ thu thập log từ 30 phút trước để giảm load
since_now = "-30m"

# Lọc theo priority: chỉ lấy error, warning, notice, info
# Bỏ qua debug và trace để giảm noise
# journalctl priority levels: 0=emerg, 1=alert, 2=crit, 3=err, 4=warning, 5=notice, 6=info, 7=debug
include_units = [
    "sshd.service",
    "systemd-logind.service", 
    "sudo.service",
    "cron.service",
    "NetworkManager.service"
]

# --------------------------------------------------------------------
# [4] AUDIT LOGS - LINUX AUDIT FRAMEWORK (AUDITD)
# --------------------------------------------------------------------
[sources.linux_audit_logs]
type = "file"
include = ["/var/log/audit/audit.log"]

# Audit logs có thể rất lớn, cần xử lý cẩn thận
max_read_bytes = 131072     # 128KB buffer
read_from = "end"           # Chỉ đọc log mới

# --------------------------------------------------------------------
# [5] NGINX/APACHE ACCESS LOGS - WEB SERVER LOGS
# --------------------------------------------------------------------
[sources.linux_web_access_logs]
type = "file"
include = [
    "/var/log/nginx/access.log",
    "/var/log/apache2/access.log",
    "/var/log/httpd/access_log"
]
read_from = "end"

# --------------------------------------------------------------------
# [6] FAIL2BAN LOGS - INTRUSION PREVENTION SYSTEM
# --------------------------------------------------------------------
[sources.linux_fail2ban_logs]
type = "file"
include = ["/var/log/fail2ban.log"]
read_from = "end"

# ====================================================================
# TRANSFORMS - XỬ LÝ VÀ CHUẨN HÓA DỮ LIỆU
# ====================================================================
# Chuyển đổi raw Linux logs thành ECS format

# --------------------------------------------------------------------
# [1] MAIN TRANSFORM - ECS NORMALIZATION ENGINE
# --------------------------------------------------------------------
[transforms.edr_ecs_normalizer]
type = "remap"
# Xử lý tất cả nguồn dữ liệu
inputs = [
    "linux_auth_logs",
    "linux_system_logs", 
    "linux_journald",
    "linux_audit_logs",
    "linux_web_access_logs",
    "linux_fail2ban_logs"
]

# VRL Script - Chuyển đổi Linux logs sang ECS format
source = '''
# ================================================================
# BƯỚC 1: THIẾT LẬP METADATA CƠ BẢN CHO MỌI EVENT
# ================================================================

# Lấy thông tin host từ biến môi trường
.host.id = get_env_var("EDR_HOST_ID") ?? uuid_v4()
.host.name = get_hostname!()
.host.os.platform = "linux"
.host.os.family = "unix"

# Detect Linux distribution
distro_info = read_file("/etc/os-release") ?? ""
if contains(distro_info, "Ubuntu") {
    .host.os.name = "Ubuntu"
} else if contains(distro_info, "CentOS") {
    .host.os.name = "CentOS"
} else if contains(distro_info, "Red Hat") {
    .host.os.name = "RHEL"
} else if contains(distro_info, "Debian") {
    .host.os.name = "Debian"
} else {
    .host.os.name = "Linux"
}

# Agent metadata
.agent.id = get_env_var("EDR_HOST_ID") ?? uuid_v4()
.agent.type = "vector-edr-linux"
.agent.version = get_env_var("VECTOR_VERSION") ?? vector_version()

# ECS compliance
.ecs.version = "8.6.0"

# Timestamp chuẩn hóa
.@timestamp = .timestamp ?? now()

# Basic event fields
.event.kind = "event"
.event.original = .message

# ================================================================
# BƯỚC 2: XỬ LÝ AUTH LOGS (SSH, SUDO, LOGIN)  
# ================================================================

if exists(.file) && (contains(.file, "auth.log") || contains(.file, "secure")) {
    .event.module = "authentication"
    .log.file.path = .file
    
    # [SSH SUCCESS LOGIN] - Đăng nhập SSH thành công
    # Pattern: "Accepted password for username from IP port PORT ssh2"
    if match(.message, r"sshd\\[\\d+\\]: Accepted") {
        .event.category = ["authentication"]
        .event.type = ["start"]
        .event.action = "ssh_login_success"
        .event.outcome = "success"
        
        # Parse SSH login success using regex
        ssh_match = parse_regex(.message, r"(?P<timestamp>\\w+\\s+\\d+\\s+\\d+:\\d+:\\d+)\\s+(?P<hostname>\\S+)\\s+sshd\\[(?P<pid>\\d+)\\]: Accepted (?P<method>\\w+) for (?P<username>\\w+) from (?P<source_ip>[\\d\\.]+) port (?P<source_port>\\d+)")
        
        if ssh_match != null {
            .user.name = ssh_match.username
            .source.ip = ssh_match.source_ip
            .source.port = to_int(ssh_match.source_port) ?? 0
            .process.pid = to_int(ssh_match.pid) ?? 0
            .process.name = "sshd"
            .network.transport = "tcp"
            .authentication.method = ssh_match.method
        }
    }
    
    # [SSH FAILED LOGIN] - Đăng nhập SSH thất bại  
    else if match(.message, r"sshd\\[\\d+\\]: Failed") {
        .event.category = ["authentication"]
        .event.type = ["start"]
        .event.action = "ssh_login_failure"
        .event.outcome = "failure"
        
        # Parse failed login
        fail_match = parse_regex(.message, r"sshd\\[(?P<pid>\\d+)\\]: Failed (?P<method>\\w+) for (?P<username>\\S+) from (?P<source_ip>[\\d\\.]+)")
        
        if fail_match != null {
            .user.name = fail_match.username
            .source.ip = fail_match.source_ip 
            .process.pid = to_int(fail_match.pid) ?? 0
            .process.name = "sshd"
            .authentication.method = fail_match.method
            
            # Detect invalid user attempts
            if contains(.message, "invalid user") {
                .event.action = "ssh_login_invalid_user"
                .user.invalid = true
            }
        }
    }
    
    # [SUDO COMMAND] - Lệnh sudo được thực thi
    else if match(.message, r"sudo:") {
        .event.category = ["process"]
        .event.type = ["start"]
        .event.action = "sudo_command"
        
        # Parse sudo command
        sudo_match = parse_regex(.message, r"sudo:\\s+(?P<username>\\w+) : TTY=(?P<tty>\\S+) ; PWD=(?P<pwd>\\S+) ; USER=(?P<target_user>\\w+) ; COMMAND=(?P<command>.*)")
        
        if sudo_match != null {
            .user.name = sudo_match.username
            .user.target.name = sudo_match.target_user
            .process.command_line = sudo_match.command
            .process.working_directory = sudo_match.pwd
            .process.tty = sudo_match.tty
        }
    }
    
    # [USER LOGIN] - User login via console/GUI
    else if match(.message, r"session opened for user") {
        .event.category = ["authentication"]
        .event.type = ["start"] 
        .event.action = "user_session_opened"
        .event.outcome = "success"
        
        user_match = parse_regex(.message, r"session opened for user (?P<username>\\w+)")
        if user_match != null {
            .user.name = user_match.username
        }
    }
}

# ================================================================
# BƯỚC 3: XỬ LÝ JOURNALD LOGS (SYSTEMD)
# ================================================================

else if exists(.host) && exists(._SYSTEMD_UNIT) {
    .event.module = "systemd"
    .systemd.unit = ._SYSTEMD_UNIT
    .systemd.user_unit = ._SYSTEMD_USER_UNIT
    
    # Process information từ journald
    .process.pid = to_int(._PID) ?? 0
    .process.executable = ._EXE
    .process.command_line = ._CMDLINE
    .process.name = ._COMM
    
    # User context
    .user.id = ._UID
    .user.group.id = ._GID
    
    # System context
    .host.boot_id = ._BOOT_ID
    .host.machine_id = ._MACHINE_ID
    
    # Message từ journald
    .message = .MESSAGE ?? .message
    
    # Phân loại theo systemd unit
    if .systemd.unit == "sshd.service" {
        .event.category = ["network", "authentication"]
        .event.action = "ssh_service_activity"
    } else if .systemd.unit == "cron.service" {
        .event.category = ["process"]
        .event.action = "cron_job_execution"
    } else if .systemd.unit == "systemd-logind.service" {
        .event.category = ["authentication"] 
        .event.action = "login_manager_activity"
    }
    
    # Clean up journald specific fields
    del(._PID)
    del(._EXE) 
    del(._CMDLINE)
    del(._COMM)
    del(._UID)
    del(._GID)
    del(._SYSTEMD_UNIT)
    del(._SYSTEMD_USER_UNIT)
    del(._BOOT_ID)
    del(._MACHINE_ID)
    del(.MESSAGE)
}

# ================================================================
# BƯỚC 4: XỬ LÝ AUDIT LOGS (AUDITD)
# ================================================================

else if exists(.file) && contains(.file, "audit.log") {
    .event.module = "auditd"
    .log.file.path = .file
    
    # Parse audit log format: type=TYPE msg=audit(timestamp:serial): fields...
    audit_match = parse_regex(.message, r"type=(?P<type>\\w+) msg=audit\\((?P<timestamp>[\\d\\.]+):\\d+\\):\\s*(?P<fields>.*)")
    
    if audit_match != null {
        .auditd.log.record_type = audit_match.type
        .auditd.log.sequence = to_int(audit_match.timestamp) ?? 0
        
        # Phân tích các loại audit record quan trọng
        if audit_match.type == "USER_LOGIN" {
            .event.category = ["authentication"]
            .event.action = "user_login"
            
            # Parse fields từ audit record
            if contains(audit_match.fields, "res=success") {
                .event.outcome = "success"
            } else {
                .event.outcome = "failure"  
            }
        } else if audit_match.type == "EXECVE" {
            .event.category = ["process"]
            .event.action = "process_execution"
            
            # Extract command execution details
            if match(audit_match.fields, r"a0=") {
                .process.args_count = count_matches(audit_match.fields, r"a\\d+=")
            }
        } else if audit_match.type == "SYSCALL" {
            .event.category = ["process"]
            .event.action = "system_call"
            
            # Parse syscall details
            syscall_match = parse_regex(audit_match.fields, r"syscall=(?P<syscall>\\d+)")
            if syscall_match != null {
                .auditd.log.syscall = syscall_match.syscall
            }
        }
    }
}

# ================================================================
# BƯỚC 5: XỬ LÝ WEB ACCESS LOGS (NGINX/APACHE)
# ================================================================

else if exists(.file) && (contains(.file, "access.log") || contains(.file, "access_log")) {
    .event.module = "web_access"
    .log.file.path = .file
    .event.category = ["web"]
    .event.action = "http_request"
    
    # Parse common log format: IP - - [timestamp] "METHOD /path HTTP/1.1" status size "referer" "user_agent"
    web_match = parse_regex(.message, r"(?P<client_ip>[\\d\\.]+) - - \\[(?P<timestamp>[^\\]]+)\\] \"(?P<method>\\w+) (?P<url>\\S+) HTTP/[\\d\\.]+\" (?P<status>\\d+) (?P<size>\\d+) \"(?P<referer>[^\"]*)\" \"(?P<user_agent>[^\"]*)\"")
    
    if web_match != null {
        .source.ip = web_match.client_ip
        .http.request.method = web_match.method
        .url.original = web_match.url
        .http.response.status_code = to_int(web_match.status) ?? 0
        .http.response.body.bytes = to_int(web_match.size) ?? 0
        .http.request.referrer = web_match.referer
        .user_agent.original = web_match.user_agent
        
        # Determine if this is a potential attack
        if .http.response.status_code >= 400 {
            .event.severity = "medium"
        }
        
        # Detect common attack patterns in URL
        if match(.url.original, r"(\\.\\./|<script|SELECT.*FROM|UNION.*SELECT)") {
            .event.action = "http_attack_attempt"
            .event.severity = "high"
        }
    }
}

# ================================================================
# BƯỚC 6: XỬ LÝ FAIL2BAN LOGS
# ================================================================

else if exists(.file) && contains(.file, "fail2ban.log") {
    .event.module = "fail2ban"
    .log.file.path = .file
    .event.category = ["intrusion_detection"]
    
    # Parse fail2ban ban action
    if match(.message, r"\\[\\w+\\] Ban") {
        .event.action = "ip_banned"
        .event.outcome = "success"
        
        ban_match = parse_regex(.message, r"\\[(?P<jail>\\w+)\\] Ban (?P<ip>[\\d\\.]+)")
        if ban_match != null {
            .source.ip = ban_match.ip
            .fail2ban.jail = ban_match.jail
        }
    } else if match(.message, r"\\[\\w+\\] Unban") {
        .event.action = "ip_unbanned"
        
        unban_match = parse_regex(.message, r"\\[(?P<jail>\\w+)\\] Unban (?P<ip>[\\d\\.]+)")
        if unban_match != null {
            .source.ip = unban_match.ip
            .fail2ban.jail = unban_match.jail
        }
    }
}

# ================================================================
# BƯỚC 7: ENRICHMENT - LÀM GIÀU DỮ LIỆU
# ================================================================

# Phân loại severity dựa trên event action
if exists(.event.action) {
    if contains(.event.action, "failure") || contains(.event.action, "failed") || contains(.event.action, "attack") {
        .event.severity = "medium"
    } else if contains(.event.action, "success") || contains(.event.action, "opened") {
        .event.severity = "low"
    }
    
    # High severity cho các hành động quan trọng
    if .event.action == "sudo_command" || .event.action == "ip_banned" {
        .event.severity = "high"  
    }
}

# Geolocate source IP nếu có (optional, có thể enable trong production)
# if exists(.source.ip) && .source.ip != "127.0.0.1" && !starts_with(.source.ip, "192.168.") && !starts_with(.source.ip, "10.") {
#     .source.geo = geoip(.source.ip, "/usr/share/GeoIP/GeoLite2-City.mmdb")
# }

# ================================================================
# BƯỚC 8: DỌN DẸP VÀ TỐI ƯU HÓA
# ================================================================

# Xóa các trường không cần thiết
del(.file)
del(.timestamp)
del(.source_type)

# Thêm metadata
.labels.environment = get_env_var("EDR_ENVIRONMENT") ?? "production"
.labels.datacenter = get_env_var("EDR_DATACENTER") ?? "default"

# Đánh dấu thời gian xử lý
.edr.processed_at = now()
.edr.agent_version = "1.0.0"

# Helper function để đếm matches
def count_matches(text, pattern) {
    matches = parse_regex_all(text, pattern) ?? []
    return length(matches)
}
'''

# ====================================================================
# SINKS - ĐÍCH ĐẾN CỦA DỮ LIỆU
# ====================================================================

# --------------------------------------------------------------------
# [1] KAFKA SINK - GỬI DỮ LIỆU ĐẾN KAFKA CLUSTER
# --------------------------------------------------------------------
[sinks.kafka_edr_events]
type = "kafka"
inputs = ["edr_ecs_normalizer"]

# Kafka cluster endpoints
bootstrap_servers = "${KAFKA_BROKERS}"

# Topic đích
topic = "edr-events-normalized"

# PARTITION KEY STRATEGY - sử dụng host.id để đảm bảo ordering
key_field = "host.id"

# Compression
compression = "lz4"

# --------------------------------------------------------------------
# [2] BUFFERING CONFIGURATION  
# --------------------------------------------------------------------
[sinks.kafka_edr_events.buffer]
type = "disk"
max_size = 2147483648  # 2GB
when_full = "block"

# --------------------------------------------------------------------
# [3] BATCH CONFIGURATION
# --------------------------------------------------------------------
[sinks.kafka_edr_events.batch]
timeout_secs = 5
max_events = 1000
max_bytes = 1048576

# --------------------------------------------------------------------
# [4] SECURITY CONFIGURATION
# --------------------------------------------------------------------
[sinks.kafka_edr_events.tls]
enabled = true
ca_file = "${TLS_CA_FILE}"

# Optional mTLS
# cert_file = "${TLS_CERT_FILE}"
# key_file = "${TLS_KEY_FILE}"

# --------------------------------------------------------------------
# [5] ERROR HANDLING
# --------------------------------------------------------------------
[sinks.kafka_edr_events.request]
retry_initial_backoff_secs = 1
retry_max_duration_secs = 300
retry_multiplier = 2
timeout_secs = 60

# ====================================================================
# HEALTHCHECK SINK
# ====================================================================
[sinks.healthcheck]
type = "http"
inputs = ["edr_ecs_normalizer"]
uri = "${HEALTHCHECK_ENDPOINT}/agent-health"
method = "POST"
encoding.codec = "json"

[sinks.healthcheck.batch]
timeout_secs = 60
max_events = 10

# ====================================================================
# LOCAL FILE SINK - BACKUP/DEBUG
# ====================================================================
# Uncomment để enable local file backup trong trường hợp mất kết nối Kafka

# [sinks.local_backup]
# type = "file"
# inputs = ["edr_ecs_normalizer"]
# path = "/var/log/vector/edr-backup-%Y-%m-%d.log"
# encoding.codec = "ndjson"
# 
# [sinks.local_backup.buffer]
# type = "disk"
# max_size = 1073741824  # 1GB
# 
# # Auto rotation
# [sinks.local_backup.file]
# max_size = 104857600   # 100MB per file

# ====================================================================
# END OF CONFIGURATION
# ====================================================================
#
# Ghi chú quan trọng:
# 1. Cấu hình này được tối ưu cho Linux endpoints trong enterprise environment
# 2. Cần review và adjust file paths cho distro cụ thể
# 3. Audit logs có thể sinh ra volume lớn - cần monitor performance
# 4. Journald integration cung cấp dữ liệu structured tốt nhất
# 5. Web access logs là optional - có thể disable nếu không cần
# 
# Biến môi trường cần thiết:
# - EDR_HOST_ID: Unique identifier cho endpoint  
# - KAFKA_BROKERS: Danh sách Kafka brokers
# - TLS_CA_FILE: CA certificate file path
# - EDR_ENVIRONMENT: Environment (dev/staging/prod)
# - EDR_DATACENTER: Datacenter identifier
# - HEALTHCHECK_ENDPOINT: Health monitoring endpoint
#
# Security considerations:
# - Vector chạy với user có quyền đọc log files
# - Rotate logs để tránh disk full
# - Monitor Vector process với systemd
# - Encrypt transport với TLS
#
# Performance tuning:
# - Adjust buffer sizes dựa trên log volume
# - Monitor CPU/memory usage của Vector
# - Tune batch sizes cho optimal throughput
#
# Author: Senior Software Engineer - EDR Platform Team
# Contact: edr-team@company.com
# Documentation: https://company.wiki/edr-platform/linux-agent
# ====================================================================
